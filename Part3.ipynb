{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Download datset from kaggle API"
      ],
      "metadata": {
        "id": "0Bh--0mnTG2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d gpiosenka/100-bird-species\n",
        "\n",
        "!unzip -q 100-bird-species.zip"
      ],
      "metadata": {
        "id": "nSFvbUl8TFo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# imports"
      ],
      "metadata": {
        "id": "Cgk6wBuxTIE5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "692P1_rvTKrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download packages"
      ],
      "metadata": {
        "id": "TQPPhwETTK7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning\n",
        "!pip install torcheval"
      ],
      "metadata": {
        "id": "DxFrGFOPTOGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build and train model\n",
        "## define transforms and device"
      ],
      "metadata": {
        "id": "QLqE7FUTTT1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "from PIL import Image\n",
        "from tempfile import TemporaryDirectory\n",
        "\n",
        "# old transformation\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((224, 224))])\n",
        "\n",
        "# this is the new transform\n",
        "transformsss = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize(256),\n",
        "    torchvision.transforms.CenterCrop(224),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.ColorJitter()\n",
        "])\n",
        "\n",
        "torch.manual_seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "YKcqRUiWTTl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the datasets\n",
        "We use ImageFolder from torchvision  "
      ],
      "metadata": {
        "id": "a8bhpyPrUbNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = torchvision.datasets.ImageFolder(\"./train\", transform = transformsss)\n",
        "train_loader = DataLoader(train_set , batch_size=64 , shuffle = True)\n",
        "\n",
        "\n",
        "validset = torchvision.datasets.ImageFolder(\"./valid\", transform = transformsss)\n",
        "validloader = torch.utils.data.DataLoader(validset , batch_size=64 , shuffle = True)\n",
        "\n",
        "testset = torchvision.datasets.ImageFolder(\"./test\", transform = transformsss)\n",
        "test_loader = torch.utils.data.DataLoader(testset , batch_size=64 , shuffle = True)"
      ],
      "metadata": {
        "id": "HePiNclZUbAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define transfer training function"
      ],
      "metadata": {
        "id": "ZcghpTEwRpy3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9axlGbVIRnb_"
      },
      "outputs": [],
      "source": [
        "def train_model(model, trainLoader, valid_loader, epochs, optimizer, scheduler, criterion):\n",
        "    '''\n",
        "    The function iterate over epochs - each iteration iterates ovr the trainloader for training and over the validationLoader for validation.\n",
        "    After training the function returns the best model.\n",
        "    The function is inspired from official pytorch docs\n",
        "    '''\n",
        "    since = time.time() # calc train time\n",
        "\n",
        "    print_every = 30\n",
        "    min_valid_loss = 0.09\n",
        "    trainloss = []\n",
        "    validloss = []\n",
        "\n",
        "    # Create a temporary directory to save training checkpoints\n",
        "    with TemporaryDirectory() as tempdir:\n",
        "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
        "        torch.save(model.state_dict(), best_model_params_path)\n",
        "        best_acc = 0.\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            print(f'Epoch {epoch}/{epochs - 1}')\n",
        "            print('-' * 10)\n",
        "\n",
        "            # the following variables used to calc accuracy and losses\n",
        "            train_loss = 0.0\n",
        "            valid_loss = 0.0\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            epoch_loss = 0.0\n",
        "\n",
        "            # training phase\n",
        "            model.train()\n",
        "            for batch_i, (images, target) in enumerate(trainLoader):\n",
        "                images = images.cuda()\n",
        "                target = target.cuda()\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                torch.set_grad_enabled(True)\n",
        "\n",
        "                # forward\n",
        "                output = model(images)\n",
        "                _, preds = torch.max(output, 1)\n",
        "                loss = criterion(output, target)\n",
        "\n",
        "                # backward\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "\n",
        "                train_loss = loss.item()\n",
        "                trainloss.append(loss.item())\n",
        "                epoch_loss += train_loss\n",
        "\n",
        "\n",
        "            scheduler.step()\n",
        "            epoch_loss = epoch_loss / len(trainLoader)\n",
        "\n",
        "            print(f'Train | Loss: {epoch_loss:.4f}')\n",
        "\n",
        "\n",
        "            running_corrects = 0\n",
        "            epoch_loss = 0.0\n",
        "            total_samples = 0\n",
        "            print()\n",
        "\n",
        "\n",
        "            # validation phase\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                for batch_i, (images, target) in enumerate(validloader):\n",
        "                    images = images.cuda()\n",
        "                    target = target.cuda()\n",
        "\n",
        "\n",
        "                    output = model(images)\n",
        "                    _, preds = torch.max(output.data, 1)\n",
        "                    loss = criterion(output, target)\n",
        "                    epoch_loss += loss.item()\n",
        "\n",
        "\n",
        "                    valid_loss = loss.item()\n",
        "                    epoch_loss += valid_loss\n",
        "                    validloss.append(valid_loss)\n",
        "\n",
        "\n",
        "                    running_corrects += torch.sum(preds == target.data)\n",
        "                    total_samples += target.size(0)\n",
        "\n",
        "\n",
        "            epoch_loss = epoch_loss / len(validloader)\n",
        "            epoch_acc = running_corrects.double() / total_samples\n",
        "            print(f'Valid | Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "\n",
        "            if epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "        print(f'Best val Acc: {best_acc:4f}')\n",
        "        model.load_state_dict(torch.load(best_model_params_path))\n",
        "    return model, trainloss, validloss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define test function"
      ],
      "metadata": {
        "id": "ysZ6CP50UAeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_loader, criterion, batch_size):\n",
        "    '''\n",
        "    This func just iterate over test_loader and calculate accuracy and the indices where the model got correct and incorrect predictions\n",
        "    '''\n",
        "    model.eval()\n",
        "    sum_losses = 0\n",
        "    total_samples = 0\n",
        "    running_corrects = 0\n",
        "\n",
        "    unique_correct_indices = []\n",
        "    unique_error_indices = []\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for iter_num, (images, target) in enumerate(test_loader):\n",
        "            images = images.cuda()\n",
        "            target = target.cuda()\n",
        "\n",
        "            output = model(images)\n",
        "            loss = criterion(output, target)\n",
        "            sum_losses += loss.item()\n",
        "\n",
        "            _, preds = torch.max(output.data, 1)\n",
        "            total_samples += target.size(0)\n",
        "\n",
        "            running_corrects += torch.sum(preds == target.data)\n",
        "\n",
        "            unique_correct_indices.extend((preds == target.data).nonzero().cpu().numpy() + (batch_size*iter_num))\n",
        "            unique_error_indices.extend((preds != target.data).nonzero().cpu().numpy() + (batch_size*iter_num))\n",
        "\n",
        "\n",
        "\n",
        "        test_acc = running_corrects/total_samples\n",
        "        test_loss = sum_losses / len(test_loader)\n",
        "    print(f\"Test acc: {test_acc}, Test loss: {test_loss}\")\n",
        "    return unique_correct_indices, unique_error_indices\n"
      ],
      "metadata": {
        "id": "FzyvQx-rUCkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the models and print results"
      ],
      "metadata": {
        "id": "N9WLkKuyUs73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# vgg19\n",
        "vgg19_model = torchvision.models.vgg19(weights=torchvision.models.VGG19_Weights.DEFAULT)\n",
        "vgg19_model.classifier[6] = nn.Linear(vgg19_model.classifier[6].in_features, 525)\n",
        "\n",
        "alexNet_model = torchvision.models.alexnet(weights=torchvision.models.AlexNet_Weights.IMAGENET1K_V1)\n",
        "for param in alexNet_model.parameters():\n",
        "        param.requires_grad = False\n",
        "alexNet_model.classifier[6] = nn.Linear(alexNet_model.classifier[6].in_features, 525)\n",
        "\n",
        "# googleNet\n",
        "googlenet_model = torchvision.models.googlenet(pretrained=True)\n",
        "\n",
        "# # resNet18\n",
        "resNet18_model = torchvision.models.resnet18(weights='IMAGENET1K_V1')\n",
        "\n",
        "# # resnet34\n",
        "resNet34_model = torchvision.models.resnet34(weights='IMAGENET1K_V1')\n",
        "\n",
        "\n",
        "pretrained_models = {'AlexNet': alexNet_model}\n",
        "                     'googlenet': googlenet_model,\n",
        "                     'resNet18': resNet18_model,\n",
        "                     'resNet34': resNet34_model}\n",
        "\n",
        "out_features = 525  # Number of classes for bird types\n",
        "uniques_indices = {}\n",
        "for model_name, model in pretrained_models.items():\n",
        "    print('\\n\\n #### Model:', model_name, \" ####\\nnum of parameters:\", sum(p.numel() for p in model.parameters()))\n",
        "\n",
        "\n",
        "\n",
        "    # put the last layer\n",
        "    if model_name != \"AlexNet\": # this condition because AlexNet is built different\n",
        "        # freeze\n",
        "        for param in model.parameters():\n",
        "          param.requires_grad = False\n",
        "\n",
        "        in_features = model.fc.in_features\n",
        "        model.fc = nn.Linear(in_features, out_features)\n",
        "\n",
        "\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss().cuda()\n",
        "    optimizer_conv = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Decay LR by a factor of 0.1 every 7 epochs\n",
        "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
        "\n",
        "    new_model, train_losses, val_losses = train_model(model, train_loader, validloader, 10, optimizer_conv, exp_lr_scheduler, criterion)\n",
        "\n",
        "    # test\n",
        "    correct_indices, error_indices = test(model, test_loader, criterion, 64)\n",
        "\n",
        "    uniques_indices[model_name] = correct_indices, error_indices\n",
        "\n"
      ],
      "metadata": {
        "id": "uO5iJVPeUvlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Count unique errors and corrects"
      ],
      "metadata": {
        "id": "C6MPCgUOVPQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy as dc\n",
        "\n",
        "def count_uniques(lsts):\n",
        "    '''\n",
        "    Function gets lists of indices for each model\n",
        "    Return: list of number of unique elements of each list\n",
        "    '''\n",
        "    lsts = dc(lsts)\n",
        "    tmp = []\n",
        "\n",
        "    uniques = []\n",
        "\n",
        "\n",
        "    for i, lst in enumerate(lsts):\n",
        "        others = np.array([lsts[x] for x in range(len(lsts)) if x != i])\n",
        "        others = [j[0] for v in others for j in v]\n",
        "\n",
        "        uniques.append(len(set([x[0] for x in lst]) - set(others)))\n",
        "\n",
        "    return uniques\n",
        "\n",
        "\n",
        "# corrects\n",
        "corrects_counts = count_uniques([x[0] for x in uniques_indices.values()])\n",
        "\n",
        "# errors\n",
        "errors_counts = count_uniques([x[1] for x in uniques_indices.values()])\n",
        "\n",
        "for i, model_name in enumerate(uniques_indices.keys()):\n",
        "  print(f\"model: {model_name}\\nunique corrects: {corrects_counts[i]}, unique errors: {errors_counts[i]}\\n\\n\")"
      ],
      "metadata": {
        "id": "P9kDPHy7VQv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7W7o04RIVTky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train classic ML model\n",
        "## Process the data"
      ],
      "metadata": {
        "id": "WQc1N-bWVqf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## define identity class as the final layer of the edited model to return prev layer values\n",
        "class Identity(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Identity, self).__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x\n",
        "\n",
        "\n",
        "FE_googlenet_model = dc(googlenet_model)\n",
        "FE_googlenet_model.fc = Identity()\n",
        "batch_size = 64\n",
        "\n",
        "x_train = []\n",
        "y_train = []\n",
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "idx = 0\n",
        "for input, label in train_loader:\n",
        "  input = input.cuda()\n",
        "  label = label.cuda()\n",
        "\n",
        "  features = FE_googlenet_model(input) # shape (64, 1024)\n",
        "\n",
        "\n",
        "  x_train += features.cpu().tolist()\n",
        "  y_train += label.tolist()\n",
        "\n",
        "\n",
        "for input, label in test_loader:\n",
        "  input = input.cuda()\n",
        "  label = label.cuda()\n",
        "\n",
        "  features = FE_googlenet_model(input) # shape (64, 1024)\n",
        "  x_test += features.cpu().tolist()\n",
        "  y_test += label.tolist()\n",
        "  # break\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "muV05WClVs80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train random forest and print results"
      ],
      "metadata": {
        "id": "qUCUUrI8V2ds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=52)\n",
        "clf = RandomForestClassifier(max_depth=10, random_state=358)\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(x_test)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "test_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "y_val_pred = clf.predict(x_val)\n",
        "val_acc = accuracy_score(y_val, y_val_pred)\n",
        "\n",
        "\n",
        "print(f\"test acc: {test_acc}, val_acc: {val_acc}\")\n",
        "f1_score(y_test, y_pred, average='micro')"
      ],
      "metadata": {
        "id": "gVpIgzMUV6z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train KNN and print results"
      ],
      "metadata": {
        "id": "YYSt8sKRV-va"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# neigh.fit(X, y)\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=52)\n",
        "clf = KNeighborsClassifier(n_neighbors=30)\n",
        "# clf = RandomForestClassifier(max_depth=10, random_state=358)\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(x_test)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "test_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "y_val_pred = clf.predict(x_val)\n",
        "val_acc = accuracy_score(y_val, y_val_pred)\n",
        "\n",
        "\n",
        "print(f\"test acc: {test_acc}, val_acc: {val_acc}\")\n",
        "f1_score(y_test, y_pred, average='micro')"
      ],
      "metadata": {
        "id": "hVYuBhQKV9f1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Test function for addition metrics like F1 score"
      ],
      "metadata": {
        "id": "2WhgG7ZiWZ3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torcheval.metrics.functional import multiclass_f1_score\n",
        "\n",
        "def test_metrics(model, test_loader, criterion, batch_size):\n",
        "    model.eval()\n",
        "    sum_losses = 0\n",
        "    total_samples = 0\n",
        "    running_corrects = 0\n",
        "\n",
        "    unique_correct_indices = []\n",
        "    unique_error_indices = []\n",
        "\n",
        "    F1s = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for iter_num, (images, target) in enumerate(test_loader):\n",
        "            images = images.cuda()\n",
        "            target = target.cuda()\n",
        "\n",
        "            output = model(images)\n",
        "            loss = criterion(output, target)\n",
        "            sum_losses += loss.item()\n",
        "\n",
        "            # total_samples += target.size(0)\n",
        "            _, preds = torch.max(output.data, 1)\n",
        "            total_samples += target.size(0)\n",
        "\n",
        "            # running_corrects += torch.sum(preds == target.data)\n",
        "            F1s += multiclass_f1_score(preds, target.data, num_classes=525).item()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        F1_score = F1s / len(test_loader)\n",
        "\n",
        "\n",
        "    print(f\"Test F1_score: {F1_score}\")\n",
        "    return None"
      ],
      "metadata": {
        "id": "Zpc3QP7PWeLr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}